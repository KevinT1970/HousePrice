{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#0. import library and get the path 加载库\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm \n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-12T02:16:59.580443Z","iopub.execute_input":"2022-01-12T02:16:59.581360Z","iopub.status.idle":"2022-01-12T02:16:59.594817Z","shell.execute_reply.started":"2022-01-12T02:16:59.581310Z","shell.execute_reply":"2022-01-12T02:16:59.593814Z"}}},{"cell_type":"code","source":"#1. Read data and describe data\n# data_file=\"train.csv\"\n\n# data=csv.loadcsv(data_file)\n\ncsv_file = os.path.join(dirname, \"train.csv\")\n# \"/kaggle/input/house-prices-advanced-regression-techniques/\"\n#csv_data是最原始的dataset，是dataframe, 38 num columns\ncsv_data = pd.read_csv(csv_file, low_memory = False)#防止弹出警告\ncsv_data.columns\ncsv_data.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:17:03.976647Z","iopub.execute_input":"2022-01-12T02:17:03.976924Z","iopub.status.idle":"2022-01-12T02:17:04.004451Z","shell.execute_reply.started":"2022-01-12T02:17:03.976895Z","shell.execute_reply":"2022-01-12T02:17:04.003808Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"#only summary the number columns, not include characters type,38 columns, but DataFrame has 81 columns\ncsv_data.describe()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:01:00.566052Z","iopub.execute_input":"2022-01-12T02:01:00.566369Z","iopub.status.idle":"2022-01-12T02:01:00.662239Z","shell.execute_reply.started":"2022-01-12T02:01:00.566334Z","shell.execute_reply":"2022-01-12T02:01:00.661365Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"csv_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:01:03.121129Z","iopub.execute_input":"2022-01-12T02:01:03.121425Z","iopub.status.idle":"2022-01-12T02:01:03.146073Z","shell.execute_reply.started":"2022-01-12T02:01:03.121392Z","shell.execute_reply":"2022-01-12T02:01:03.145200Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"csv_data.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:01:07.806244Z","iopub.execute_input":"2022-01-12T02:01:07.806578Z","iopub.status.idle":"2022-01-12T02:01:07.832277Z","shell.execute_reply.started":"2022-01-12T02:01:07.806542Z","shell.execute_reply":"2022-01-12T02:01:07.831364Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"#df is the DataFrame for data analyse, analyse data with the backup dataset\n# df = csv_data\ndf = pd.DataFrame(csv_data)\n# df=pd.DataFrame(data[0])\n#when change the type of df, the original csc_data dtype will be change as well.!\n# 所以下面代码不需要\n# for col in df.columns:\n#     #change 'object' type \n#   if df[col].dtype=='object':\n#     #making sure data is not read as bytes but as string values from a file\n#     df[col] = df[col].str.decode('utf-8')\n#Look at loaded data and data types\n\nprint(df.dtypes)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:17:15.883616Z","iopub.execute_input":"2022-01-12T02:17:15.884520Z","iopub.status.idle":"2022-01-12T02:17:15.892581Z","shell.execute_reply.started":"2022-01-12T02:17:15.884468Z","shell.execute_reply":"2022-01-12T02:17:15.891498Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"df.head()\n# after change object to floats64, these data is NaN, can't be use","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:01:20.210597Z","iopub.execute_input":"2022-01-12T02:01:20.211030Z","iopub.status.idle":"2022-01-12T02:01:20.247877Z","shell.execute_reply.started":"2022-01-12T02:01:20.210982Z","shell.execute_reply":"2022-01-12T02:01:20.246577Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:01:25.976419Z","iopub.execute_input":"2022-01-12T02:01:25.977153Z","iopub.status.idle":"2022-01-12T02:01:25.999958Z","shell.execute_reply.started":"2022-01-12T02:01:25.977105Z","shell.execute_reply":"2022-01-12T02:01:25.998816Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"df.describe()\n# df.describe(exclude='float64')","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:01:33.945537Z","iopub.execute_input":"2022-01-12T02:01:33.946402Z","iopub.status.idle":"2022-01-12T02:01:34.050026Z","shell.execute_reply.started":"2022-01-12T02:01:33.946258Z","shell.execute_reply":"2022-01-12T02:01:34.049386Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:01:37.117397Z","iopub.execute_input":"2022-01-12T02:01:37.118109Z","iopub.status.idle":"2022-01-12T02:01:37.141681Z","shell.execute_reply.started":"2022-01-12T02:01:37.118059Z","shell.execute_reply":"2022-01-12T02:01:37.140547Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"#change YrSold, MoSold to datetime type\ndf.YrSold = pd.to_datetime(df.YrSold, format='%Y')\ndf.MoSold = pd.to_datetime(df.MoSold, format='%m')\ndf.info()\n# crime.Year = pd.to_datetime(crime.Year, format='%Y')\n# crime.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:17:25.891888Z","iopub.execute_input":"2022-01-12T02:17:25.892442Z","iopub.status.idle":"2022-01-12T02:17:25.923599Z","shell.execute_reply.started":"2022-01-12T02:17:25.892387Z","shell.execute_reply":"2022-01-12T02:17:25.921454Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"# fail to map MSZoning to series, should find the reseaon later.\n# s = pd.Series([\"FV\",\"RH\",\"RL\",\"RM\", \"C\"],index = [1,2,3,4,5])\n# df['MSZoning']=df['MSZoning'].map({'FV':1,'RH':2,'RL':3,'RM':4, 'C':5 }).astype(int)     #将MSZoning中的字符串变成对应的数字表示\n\n# df['MSZoning']=df['MSZoning'].map({'RL':1,'RM':2,'RR':3,}).astype(int)     #将MSZoning中的字符串变成对应的数字表示","metadata":{"execution":{"iopub.status.busy":"2022-01-11T03:43:54.494541Z","iopub.execute_input":"2022-01-11T03:43:54.4953Z","iopub.status.idle":"2022-01-11T03:43:54.498536Z","shell.execute_reply.started":"2022-01-11T03:43:54.495257Z","shell.execute_reply":"2022-01-11T03:43:54.497899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#2. corralation analyse: use select_dtype() to filter dtype\n# df_num = df.select_dtypes(include='int64', exclude='float64')\ndf_num = df.select_dtypes(include='int64')\n# df_num = df.where(Id > 3)\n# df_num = pd.DataFrame(data=df, dtype=np.int64)dt_num = np.dtype(np.int32)\n# df_num = pd.DataFrame(df, dtype=np.float64)\n# df_num = df.dtype(np.int64)\n# df_num = df.where(df['Id']<3)\n# df_num = df.where(df.dtype(int64))\n# df_num = df[[df.columns.dtype]=int64]\n# df_num = df[[df.columns.dtype]]\ndf_num.head()\n\n# df.columns\n# df_num = df[col].dtype=='object'\n# dt_num.head()\n# df_num.describe()\n# corr_num = df_num.corr()\n# print(corr_num)\n# print(corr_num)\n# corr_matrix = df.corr()\n# corr_matrix = df.corr()\n# print(corr_matrix)\n# print(which(corr_matrix != NaN)\n# print(abs(corr_matrix)>0.03)\n# main related elements: MSSubClass, LotFrontage, LotArea, MoSold, YrSold, SalePrice, PoolArea, ","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:17:33.038158Z","iopub.execute_input":"2022-01-12T02:17:33.038731Z","iopub.status.idle":"2022-01-12T02:17:33.061783Z","shell.execute_reply.started":"2022-01-12T02:17:33.038688Z","shell.execute_reply":"2022-01-12T02:17:33.060718Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"#analyse the relation for number columns\ndf_num_mt = df_num.corr()\n# print(abs(df_num_mt) > 0.03)\nprint(df_num_mt)\n#and  find the most related columns from the big matrix\n# MSSubClass,LotArea, OverallQual, OverallCond,YearBuilt,YearRemodAdd,BsmtFinSF1, BsmtUnfSF,GarageCars, GarageArea,\n# WoodDeckSF,  OpenPorchSF,EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea, SalePrice ","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:17:36.043150Z","iopub.execute_input":"2022-01-12T02:17:36.043748Z","iopub.status.idle":"2022-01-12T02:17:36.071428Z","shell.execute_reply.started":"2022-01-12T02:17:36.043699Z","shell.execute_reply":"2022-01-12T02:17:36.070562Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"#To determine the most related elements with the saleprice through compare， at least corralation biger the 0.03\n# MSSubClass,LotArea, OverallQual, OverallCond,YearBuilt,YearRemodAdd,BsmtFinSF1, BsmtUnfSF,GarageCars, GarageArea,\n# WoodDeckSF,  OpenPorchSF,EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea, SalePrice \n# df_highcorr = df[['MSSubClass'','LotArea', '''OverallQua'l'', 'Overal'l'Cond','Yea'rB'uilt','YearRemodAdd','BsmtFinSF1', 'BsmtUnfSF','GarageCars', 'GarageArea','WoodDeckSF',  'OpenPorchSF','EnclosedPorch',  '3SsnPorch',  'ScreenPorch',  'PoolArea', 'SalePrice']]\n# df_highcorr1 = df[['MSSubClass','LotArea', 'OverallQual', 'OverallCond','YearBuilt','YearRemodAdd',\n#                   'BsmtFinSF1', 'BsmtUnfSF','GarageCars', 'GarageArea','WoodDeckSF',  'OpenPorchSF',\n#                   'EnclosedPorch',  '3SsnPorch',  'ScreenPorch',  'PoolArea', 'SalePrice']]\ndf_highcorr1 = df[['LotArea', 'OverallQual', 'OverallCond','YearBuilt','YearRemodAdd',\n                  'BsmtFinSF1', 'BsmtUnfSF','GarageCars', 'GarageArea','WoodDeckSF',  'OpenPorchSF',\n                  'EnclosedPorch',  '3SsnPorch',  'ScreenPorch',  'PoolArea', 'SalePrice']]\n#remove the MSSubClass, 3SsnPorch, and save data to the subset.\n# these 15 columns more related.\ndf_highcorr = df[['LotArea', 'OverallQual', 'OverallCond','YearBuilt','YearRemodAdd',\n                  'BsmtFinSF1', 'BsmtUnfSF','GarageCars', 'GarageArea','WoodDeckSF',\n                  'OpenPorchSF', 'EnclosedPorch',  'ScreenPorch',  'PoolArea', 'SalePrice']].corr()\n\nprint(df_highcorr)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:17:43.855651Z","iopub.execute_input":"2022-01-12T02:17:43.856182Z","iopub.status.idle":"2022-01-12T02:17:43.876218Z","shell.execute_reply.started":"2022-01-12T02:17:43.856142Z","shell.execute_reply":"2022-01-12T02:17:43.875143Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"#Draw the heatmap of the corralation\n\n# corr_matrix = df.corr()\n# sns.heatmap(corr_matrix, vmax=1, vmin=-1, center=0)\n#方法1\nmask = np.array(df_highcorr)\nmask[np.tril_indices_from(mask)] = False\nplt.subplots(figsize=(20,10))\nplt.xticks(rotation=60)#设置刻度标签角度\n# sns.heatmap(corrMat, mask=mask,vmax=.8, square=True,annot=True)\nsns.heatmap(df_highcorr, mask=mask, vmax=1, vmin=-1, center=0, cmap='Blues', fmt=\".2f\", annot=True, \n           annot_kws={'size':12,'weight':'normal', 'color':'black'})\n#方法2\n# plt.figure(dpi=120)\n# sns.heatmap(df_highcorr, vmax=1, vmin=-1, center=0, cmap='Blues', fmt=\".2f\", annot=True, \n#            annot_kws={'size':6,'weight':'normal', 'color':'black'})\n# sns.heatmap(df_highcorr, cmap='Blues')\n\nplt.show()\nplt.savefig('heatmap_corr.png')          \n","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:17:47.990062Z","iopub.execute_input":"2022-01-12T02:17:47.990398Z","iopub.status.idle":"2022-01-12T02:17:48.912752Z","shell.execute_reply.started":"2022-01-12T02:17:47.990362Z","shell.execute_reply":"2022-01-12T02:17:48.911721Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"#scatterplot\nsns.set()\ncols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n# cols = ['LotArea', 'OverallQual', 'OverallCond','YearBuilt','YearRemodAdd',\n#                   'BsmtFinSF1', 'BsmtUnfSF','GarageCars', 'GarageArea','WoodDeckSF',\n#                   'OpenPorchSF', 'EnclosedPorch',  'ScreenPorch',  'PoolArea', 'SalePrice']\nsns.pairplot(df[cols], size = 2.5)\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:18:11.985270Z","iopub.execute_input":"2022-01-12T02:18:11.985599Z","iopub.status.idle":"2022-01-12T02:18:20.963636Z","shell.execute_reply.started":"2022-01-12T02:18:11.985562Z","shell.execute_reply":"2022-01-12T02:18:20.962565Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"#3. The key element is saleprice, but it is not normal, has lots of dirty data, need to clean, \nsns.boxplot(y='SalePrice', data=df)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:18:31.106657Z","iopub.execute_input":"2022-01-12T02:18:31.106954Z","iopub.status.idle":"2022-01-12T02:18:31.292037Z","shell.execute_reply.started":"2022-01-12T02:18:31.106920Z","shell.execute_reply":"2022-01-12T02:18:31.291173Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"#矫正前的偏移度\nskew1 = df['SalePrice'].skew()\nprint(skew1)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:18:37.783366Z","iopub.execute_input":"2022-01-12T02:18:37.783898Z","iopub.status.idle":"2022-01-12T02:18:37.789370Z","shell.execute_reply.started":"2022-01-12T02:18:37.783861Z","shell.execute_reply":"2022-01-12T02:18:37.788541Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"# analyse, saleprice is not normal, need to clean\nsns.boxplot(x='OverallQual', y='SalePrice', data=df, palette='Set3')","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:18:40.798263Z","iopub.execute_input":"2022-01-12T02:18:40.798924Z","iopub.status.idle":"2022-01-12T02:18:41.186614Z","shell.execute_reply.started":"2022-01-12T02:18:40.798874Z","shell.execute_reply":"2022-01-12T02:18:41.185667Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"#box plot overallqual/saleprice\nvar = 'OverallQual'\ndata = pd.concat([df['SalePrice'], df[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nfig.axis(ymin=0, ymax=800000);\nplt.xticks(rotation=90);","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:18:50.202833Z","iopub.execute_input":"2022-01-12T02:18:50.203357Z","iopub.status.idle":"2022-01-12T02:18:50.584847Z","shell.execute_reply.started":"2022-01-12T02:18:50.203321Z","shell.execute_reply":"2022-01-12T02:18:50.583929Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"# import scipy.stats as norm  \n\n#transformed histogram and normal probability plot\nsns.distplot(df['SalePrice'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df['SalePrice'], plot=plt)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:19:20.901728Z","iopub.execute_input":"2022-01-12T02:19:20.902036Z","iopub.status.idle":"2022-01-12T02:19:21.294383Z","shell.execute_reply.started":"2022-01-12T02:19:20.902004Z","shell.execute_reply":"2022-01-12T02:19:21.293155Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"#矫正后的偏移度\nskew2 = df['SalePrice'].skew()\nprint(skew2)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:07:12.205858Z","iopub.execute_input":"2022-01-12T02:07:12.206244Z","iopub.status.idle":"2022-01-12T02:07:12.225098Z","shell.execute_reply.started":"2022-01-12T02:07:12.206208Z","shell.execute_reply":"2022-01-12T02:07:12.224133Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"df['SalePrice'].describe()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:20:10.105050Z","iopub.execute_input":"2022-01-12T02:20:10.105750Z","iopub.status.idle":"2022-01-12T02:20:10.116662Z","shell.execute_reply.started":"2022-01-12T02:20:10.105707Z","shell.execute_reply":"2022-01-12T02:20:10.115436Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"df.SalePrice.median()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:20:15.668181Z","iopub.execute_input":"2022-01-12T02:20:15.668462Z","iopub.status.idle":"2022-01-12T02:20:15.675101Z","shell.execute_reply.started":"2022-01-12T02:20:15.668434Z","shell.execute_reply":"2022-01-12T02:20:15.674038Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"df.SalePrice.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:07:22.216660Z","iopub.execute_input":"2022-01-12T02:07:22.216979Z","iopub.status.idle":"2022-01-12T02:07:22.225997Z","shell.execute_reply.started":"2022-01-12T02:07:22.216942Z","shell.execute_reply":"2022-01-12T02:07:22.225173Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"df['SalePrice'].quantile(0.25)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:20:20.954387Z","iopub.execute_input":"2022-01-12T02:20:20.954682Z","iopub.status.idle":"2022-01-12T02:20:20.962707Z","shell.execute_reply.started":"2022-01-12T02:20:20.954649Z","shell.execute_reply":"2022-01-12T02:20:20.961742Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"percentile_99 = df['SalePrice'].quantile(0.99)\npercentile_99","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:20:42.056789Z","iopub.execute_input":"2022-01-12T02:20:42.057566Z","iopub.status.idle":"2022-01-12T02:20:42.064586Z","shell.execute_reply.started":"2022-01-12T02:20:42.057526Z","shell.execute_reply":"2022-01-12T02:20:42.063983Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"df[df.SalePrice > percentile_99]","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:20:46.003847Z","iopub.execute_input":"2022-01-12T02:20:46.004158Z","iopub.status.idle":"2022-01-12T02:20:46.035093Z","shell.execute_reply.started":"2022-01-12T02:20:46.004128Z","shell.execute_reply":"2022-01-12T02:20:46.034292Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"percentile_01 = df['SalePrice'].quantile(0.01)\npercentile_01\ndf[df.SalePrice < percentile_01]","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:20:50.991449Z","iopub.execute_input":"2022-01-12T02:20:50.991743Z","iopub.status.idle":"2022-01-12T02:20:51.033904Z","shell.execute_reply.started":"2022-01-12T02:20:50.991713Z","shell.execute_reply":"2022-01-12T02:20:51.033026Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"#to many data out 99% and 1%, so we can't say these are outlier data.\ndf_out01_99 = df['SalePrice'][(df.SalePrice < percentile_01) & (df.SalePrice) > percentile_99]\ndf_out01_99","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:20:56.609723Z","iopub.execute_input":"2022-01-12T02:20:56.610273Z","iopub.status.idle":"2022-01-12T02:20:56.618796Z","shell.execute_reply.started":"2022-01-12T02:20:56.610222Z","shell.execute_reply":"2022-01-12T02:20:56.617903Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"# df_no_outlier = df[df.SalePrice <= percentile_99  df.SalePrce >= percentile_01]\n# df_no_outlier = df['SalePrice'][df['SalePrice'] < percentile_99 ]\ndf_no_out01_99 = df['SalePrice'][(df.SalePrice > percentile_01) | (df.SalePrice) < percentile_99]\ndf_no_out01_99","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:21:41.194845Z","iopub.execute_input":"2022-01-12T02:21:41.195831Z","iopub.status.idle":"2022-01-12T02:21:41.208449Z","shell.execute_reply.started":"2022-01-12T02:21:41.195769Z","shell.execute_reply":"2022-01-12T02:21:41.207497Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"#将3sigma范围之外的异常数据找出来\nmu = np.mean(df['SalePrice'])\nsigma = np.std(df['SalePrice'])\n\noutlier = df['SalePrice'][(df['SalePrice'] > mu + 3*sigma) |  (df['SalePrice'] < mu - 3*sigma)]\n# outlier1 = df['SalePrice'][(df['SalePrice'] > mu + 3*sigma)]\nprint(outlier)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:22:16.410038Z","iopub.execute_input":"2022-01-12T02:22:16.410289Z","iopub.status.idle":"2022-01-12T02:22:16.419367Z","shell.execute_reply.started":"2022-01-12T02:22:16.410263Z","shell.execute_reply":"2022-01-12T02:22:16.418347Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"df_no_outlier = df['SalePrice'][(df['SalePrice'] < mu + 3*sigma) & (df['SalePrice'] > mu - 3*sigma)]","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:22:23.195968Z","iopub.execute_input":"2022-01-12T02:22:23.196264Z","iopub.status.idle":"2022-01-12T02:22:23.202115Z","shell.execute_reply.started":"2022-01-12T02:22:23.196235Z","shell.execute_reply":"2022-01-12T02:22:23.201200Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"#histogram\nsns.distplot(df['SalePrice']);","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:22:27.497195Z","iopub.execute_input":"2022-01-12T02:22:27.497498Z","iopub.status.idle":"2022-01-12T02:22:27.867539Z","shell.execute_reply.started":"2022-01-12T02:22:27.497466Z","shell.execute_reply":"2022-01-12T02:22:27.866640Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"# 对数转换：右偏数据，不适用于左偏数据,若数据中有正有负，可以如下转换：\n# df['SalePrice'] = np.sign(df['SalePrice'])*np.log(np.abs(df['SalePrice'])+1)\n#applying log transformation\ndf['SalePrice'] = np.log(df_no_outlier)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:28:47.435613Z","iopub.execute_input":"2022-01-12T02:28:47.435916Z","iopub.status.idle":"2022-01-12T02:28:47.441770Z","shell.execute_reply.started":"2022-01-12T02:28:47.435884Z","shell.execute_reply":"2022-01-12T02:28:47.440572Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"sns.distplot(df_no_outlier);","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:28:51.433256Z","iopub.execute_input":"2022-01-12T02:28:51.433864Z","iopub.status.idle":"2022-01-12T02:28:51.791159Z","shell.execute_reply.started":"2022-01-12T02:28:51.433822Z","shell.execute_reply":"2022-01-12T02:28:51.790317Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"#矫正后的偏移度\nskew2 = df_no_outlier.skew()\nprint(skew2)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:28:57.046151Z","iopub.execute_input":"2022-01-12T02:28:57.046960Z","iopub.status.idle":"2022-01-12T02:28:57.052238Z","shell.execute_reply.started":"2022-01-12T02:28:57.046917Z","shell.execute_reply":"2022-01-12T02:28:57.051199Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"#将3sigma范围之外的异常数据找出来","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print boxplot after adjust skew()\nsns.boxplot(y='SalePrice', data=df)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:29:02.545901Z","iopub.execute_input":"2022-01-12T02:29:02.546579Z","iopub.status.idle":"2022-01-12T02:29:02.721599Z","shell.execute_reply.started":"2022-01-12T02:29:02.546543Z","shell.execute_reply":"2022-01-12T02:29:02.720608Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#打印价格的正态分布图\n# import matplotlib.pyplot as plt\n#方法1\n#正态分布的概率密度函数\ndef normpdf(x,mu,sigma):       \n    pdf=np.exp(-(x-mu)**2/(2*sigma**2))/(sigma * np.sqrt(2 * np.pi))\n    return pdf\n# mu,sigma=eval(input()) #mu:期望;sigma:标准差 \nmu = np.mean(df['SalePrice'])\nsigma = np.var(df['SalePrice'])\nx= np.arange(mu-3*sigma,mu+3*sigma,0.01) #生成数据，步长越小，曲线越平滑\ny=normpdf(x,mu,sigma)\n\n#概率分布曲线\nplt.plot(x,y,'g--',linewidth=2)\nplt.title('Normal Distribution: mu = {:.2f}, sigma={:.2f}'.format(mu,sigma))\nplt.vlines(mu, 0, normpdf(mu,mu,sigma), colors = \"c\", linestyles = \"dotted\")\nplt.vlines(mu+sigma, 0, normpdf(mu+sigma,mu,sigma), colors = \"y\", linestyles = \"dotted\")\nplt.vlines(mu-sigma, 0, normpdf(mu-sigma,mu,sigma), colors = \"y\", linestyles = \"dotted\")\nplt.xticks ([mu-sigma,mu,mu+sigma],['μ-σ','μ','μ+σ'])\n\n#输出\nplt.grid()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:29:07.760077Z","iopub.execute_input":"2022-01-12T02:29:07.760384Z","iopub.status.idle":"2022-01-12T02:29:07.953345Z","shell.execute_reply.started":"2022-01-12T02:29:07.760348Z","shell.execute_reply":"2022-01-12T02:29:07.952515Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"# 方法2：采用seaborn库中的distplot绘制\nsns.set_palette(\"hls\") #设置所有图的颜色，使用hls色彩空间\nsns.distplot(df['SalePrice'],color=\"r\",bins=30,kde=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:29:12.285574Z","iopub.execute_input":"2022-01-12T02:29:12.285866Z","iopub.status.idle":"2022-01-12T02:29:12.585004Z","shell.execute_reply.started":"2022-01-12T02:29:12.285832Z","shell.execute_reply":"2022-01-12T02:29:12.583987Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"# 方法3：\nx = df['SalePrice'] #提取变量 \nmu =np.mean(x) #计算均值 \nsigma =np.std(x) \nmu,sigma\n\nnum_bins = 30 #直方图柱子的数量 \nn, bins, patches = plt.hist(x, num_bins,normed=1, facecolor='blue', alpha=0.5) \n#直方图函数，x为x轴的值，normed=1表示为概率密度，即和为一，绿色方块，色深参数0.5.返回n个概率，直方块左边线的x值，及各个方块对象 \ny = mlab.normpdf(bins, mu, sigma)#拟合一条最佳正态分布曲线y \nplt.plot(bins, y, 'r--') #绘制y的曲线 \nplt.xlabel('sepal-length') #绘制x轴 \nplt.ylabel('Probability') #绘制y轴 \nplt.title(r'Histogram : $\\mu=5.8433$,$\\sigma=0.8253$')#中文标题 u'xxx' \nplt.subplots_adjust(left=0.15)#左边距 \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:29:16.475043Z","iopub.execute_input":"2022-01-12T02:29:16.475521Z","iopub.status.idle":"2022-01-12T02:29:16.806367Z","shell.execute_reply.started":"2022-01-12T02:29:16.475484Z","shell.execute_reply":"2022-01-12T02:29:16.804869Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"# 方法4：另一种方法打印正态曲线\nprint('df[SalePrice] shape={}'.format(df['SalePrice'].shape))\n# df['SalePrice'].shape\ndf['SalePrice'].hist(bins=1460)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:29:37.738464Z","iopub.execute_input":"2022-01-12T02:29:37.739043Z","iopub.status.idle":"2022-01-12T02:29:40.871103Z","shell.execute_reply.started":"2022-01-12T02:29:37.739000Z","shell.execute_reply":"2022-01-12T02:29:40.869473Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"#以下代码不需要，作为备注保留 \n# sub_df = df['MSSubClass', 'SalePrice']\n# sub_df = pd.dataframe(df['Id'],df['SalePrice'])\n# subset = df[['MSSubClass','LotFrontage', 'LotArea', 'MoSold', 'YrSold', 'PoolArea', 'SalePrice']]\n# print(subset.corr())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_style('whitegrid')\n\ndef three_chart_plot(df, feature):\n\n    fig = plt.figure(constrained_layout = True, figsize = (12, 8))\n    grid = gridspec.GridSpec(ncols = 3, nrows = 3, figure = fig)\n    \n    ax1 = fig.add_subplot(grid[0, :2])\n    ax1.set_title('Histogram')\n    \n    sns.distplot(df.loc[:, feature], norm_hist = True, ax = ax1)\n    plt.axvline(x = df[feature].mean(), c = 'red')\n    plt.axvline(x = df[feature].median(), c = 'green')\n    \n    ax2 = fig.add_subplot(grid[1, :2])\n    ax2.set_title('QQ_plot')\n    stats.probplot(df.loc[:,feature], plot = ax2)\n\n    ## Customizing the Box Plot. \n    ax3 = fig.add_subplot(grid[:, 2])\n\n    ## Set title. \n    ax3.set_title('Box Plot')\n    sns.boxplot(df.loc[:,feature], ax = ax3 ,orient = 'v')\n","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:29:45.826603Z","iopub.execute_input":"2022-01-12T02:29:45.826915Z","iopub.status.idle":"2022-01-12T02:29:45.836381Z","shell.execute_reply.started":"2022-01-12T02:29:45.826878Z","shell.execute_reply":"2022-01-12T02:29:45.835260Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"three_chart_plot(df, 'SalePrice');","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:29:53.878822Z","iopub.execute_input":"2022-01-12T02:29:53.879097Z","iopub.status.idle":"2022-01-12T02:29:53.907954Z","shell.execute_reply.started":"2022-01-12T02:29:53.879066Z","shell.execute_reply":"2022-01-12T02:29:53.907122Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#4. clean data for preparation, 以下是数据清理\n#missing data\ntotal = df.isnull().sum().sort_values(ascending=False)\npercent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:30:07.486845Z","iopub.execute_input":"2022-01-12T02:30:07.487757Z","iopub.status.idle":"2022-01-12T02:30:07.517839Z","shell.execute_reply.started":"2022-01-12T02:30:07.487717Z","shell.execute_reply":"2022-01-12T02:30:07.516999Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"\n#列级别的判断，只要该列有为空或者NA的元素，就为True，否则False\n# df.isnull().any()\n#将为空或者NA的列找出来\nmissing=df.columns[df.isnull().any()].tolist()  \nprint(missing)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:30:17.639370Z","iopub.execute_input":"2022-01-12T02:30:17.640147Z","iopub.status.idle":"2022-01-12T02:30:17.651150Z","shell.execute_reply.started":"2022-01-12T02:30:17.640106Z","shell.execute_reply":"2022-01-12T02:30:17.650068Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"#calculate the NaN rows\ndf[missing].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:30:20.660043Z","iopub.execute_input":"2022-01-12T02:30:20.660353Z","iopub.status.idle":"2022-01-12T02:30:20.672797Z","shell.execute_reply.started":"2022-01-12T02:30:20.660318Z","shell.execute_reply":"2022-01-12T02:30:20.671816Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"# 将某一列中缺失元素的值，用value值进行填充。处理缺失数据时，比如该列都是字符串，不是数值，可以将出现次数最多的字符串填充缺失值。\ndef cat_imputation(column, value):\n    df.loc[df[column].isnull(),column] = value","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:30:23.931391Z","iopub.execute_input":"2022-01-12T02:30:23.931815Z","iopub.status.idle":"2022-01-12T02:30:23.935933Z","shell.execute_reply.started":"2022-01-12T02:30:23.931784Z","shell.execute_reply":"2022-01-12T02:30:23.935052Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"df[['LotFrontage','Alley']][df['Alley'].isnull()==True]      \n#从LotFrontage 和Alley 列中进行选择行，选择Alley中数据为空的行。主要用来看两个列的关联程度，是不是大多同时为空。","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:30:25.904230Z","iopub.execute_input":"2022-01-12T02:30:25.904552Z","iopub.status.idle":"2022-01-12T02:30:25.921232Z","shell.execute_reply.started":"2022-01-12T02:30:25.904518Z","shell.execute_reply":"2022-01-12T02:30:25.920541Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"df['Fireplaces'][df['FireplaceQu'].isnull()==True].describe()   \n#对筛选出来的数据做一个描述，比如一共多少行，均值、方差、最小值、最大值等等。","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:30:28.452274Z","iopub.execute_input":"2022-01-12T02:30:28.452771Z","iopub.status.idle":"2022-01-12T02:30:28.463388Z","shell.execute_reply.started":"2022-01-12T02:30:28.452721Z","shell.execute_reply":"2022-01-12T02:30:28.462379Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"df['MSSubClass'].value_counts()         #统计某一列中各个元素值出现的次数","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:30:30.797806Z","iopub.execute_input":"2022-01-12T02:30:30.799164Z","iopub.status.idle":"2022-01-12T02:30:30.807780Z","shell.execute_reply.started":"2022-01-12T02:30:30.799103Z","shell.execute_reply":"2022-01-12T02:30:30.806797Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"print(\"Skewness: %f\" % df['MSSubClass'].skew())    #列出数据的偏斜度\nprint(\"Kurtosis: %f\" % df['MSSubClass'].kurt())  #列出数据的峰度","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:30:33.631382Z","iopub.execute_input":"2022-01-12T02:30:33.631984Z","iopub.status.idle":"2022-01-12T02:30:33.638726Z","shell.execute_reply.started":"2022-01-12T02:30:33.631948Z","shell.execute_reply":"2022-01-12T02:30:33.637625Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"df['LotFrontage'].corr(df['LotArea'])         #计算两个列的相关度","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:30:36.338666Z","iopub.execute_input":"2022-01-12T02:30:36.338956Z","iopub.status.idle":"2022-01-12T02:30:36.345733Z","shell.execute_reply.started":"2022-01-12T02:30:36.338923Z","shell.execute_reply":"2022-01-12T02:30:36.344874Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"df['SqrtLotArea']=np.sqrt(df['LotArea'])   #将列的数值求根，并赋予一个新列\ndf[['MSSubClass', 'LotFrontage']].groupby(['MSSubClass'], as_index=False).mean()  #跟MSSubClass进行分组，并求分组后的平均值","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df['SqrtLotArea']       #删除列\n\ndf['LotFrontage'].dropna()   #去掉为空值或者NA的元素\n\ndf.drop(['Alley'],axis=1)     #去掉Alley列，不管空值与否\n\ndf.drop(df.columns[[0,1]],axis=1,inplace=True)  #删除第1，2列，inplace=True表示直接就在内存中替换了，不用二次赋值生效。\n\ndf.dropna(axis=0)         #删除带有空值的行\n\ndf.dropna(axis=1)        #删除带有空值的列","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:30:46.632230Z","iopub.execute_input":"2022-01-12T02:30:46.632902Z","iopub.status.idle":"2022-01-12T02:30:46.682540Z","shell.execute_reply.started":"2022-01-12T02:30:46.632860Z","shell.execute_reply":"2022-01-12T02:30:46.681254Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"df['LotFrontage']=df['LotFrontage'].fillna(0)   #将该列中的空值或者NA填充为0\n# csv_data.product_type[all_data.product_type.isnull()]=csv_data.product_type.dropna().mode().values    #如果该列是字符串的，就将该列中出现次数最多的字符串赋予空值,mode()函数就是取出现次数最多的元素。\ndf['LotFrontage'].fillna(method='pad') #使用前一个数值替代空值或者NA，就是NA前面最近的非空数值替换     \ndf['LotFrontage'].fillna(method='bfill',limit=1) #使用后一个数值替代空值或者NA，limit=1就是限制如果几个连续的空值，只能最近的一个空值可以被填充。\ndf['LotFrontage'].fillna(df['LotFrontage'].mean()) #使用平均值进行填充\ndf['LotFrontage'].interpolate() # 使用插值来估计NaN 如果index是数字，可以设置参数method='value' ，如果是时间，可以设置method='time'\ndf= df.fillna(df.mean()) #将缺失值全部用该列的平均值代替，这个时候一般已经提前将字符串特征转换成了数值。","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:30:53.524682Z","iopub.execute_input":"2022-01-12T02:30:53.525539Z","iopub.status.idle":"2022-01-12T02:30:53.564464Z","shell.execute_reply.started":"2022-01-12T02:30:53.525498Z","shell.execute_reply":"2022-01-12T02:30:53.563455Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:31:02.525994Z","iopub.execute_input":"2022-01-12T02:31:02.526934Z","iopub.status.idle":"2022-01-12T02:31:02.620914Z","shell.execute_reply.started":"2022-01-12T02:31:02.526883Z","shell.execute_reply":"2022-01-12T02:31:02.620053Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"# 5.Machine learning\n\n#for bank dataset uncomment following line\ncat_cols=['LotArea', 'OverallQual', 'OverallCond','YearBuilt','YearRemodAdd',\n                  'BsmtFinSF1', 'BsmtUnfSF','GarageCars', 'GarageArea','WoodDeckSF',\n                  'OpenPorchSF', 'EnclosedPorch',  'ScreenPorch',  'PoolArea', 'SalePrice']\n# Create a copy of the data frame in memory with a different name\ndf_onehot=df.copy()\n#convert only categorical variables/features to dummy/one-hot features\ndf_onehot = pd.get_dummies(df, columns=cat_cols, prefix = cat_cols)\n#print the dataset\ndf_onehot\n","metadata":{"execution":{"iopub.status.busy":"2022-01-10T02:11:24.758834Z","iopub.execute_input":"2022-01-10T02:11:24.759137Z","iopub.status.idle":"2022-01-10T02:11:24.862422Z","shell.execute_reply.started":"2022-01-10T02:11:24.759104Z","shell.execute_reply":"2022-01-10T02:11:24.861377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ## For Bank data set only\n# ####\n# # in the case of bank data set, pdays and balance columns have negative values. Those columns won't work with Naive Bayes. So run the following\n# # line of code for bank data set to make negative values to 0. Note that it is not necessary for decision tree to remove negative values.\n# df_onehot[\"SalePrice\"]=df_onehot[\"pdays\"].apply(lambda x: 0 if x<0 else x)\n# df_onehot[\"balance\"]=df_onehot[\"balance\"].apply(lambda x: 0 if x<0 else x)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Repeat the train test set split\nfrom sklearn.model_selection import train_test_split\n# class_col_name=\"Creditability\"\n# Uncomment following line for class name for bank dataset\nclass_col_name=\"y\"\n# Uncomment following line for class name for Churn dataset\n# class_col_name=\"Churn\"\none_hot_feature_names=df_onehot.columns[df_onehot.columns != class_col_name]\n# Split dataset into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(df_onehot.loc[:, one_hot_feature_names], df_onehot[class_col_name], test_size=0.3,random_state=109) # 70% training and 30% test\n","metadata":{"execution":{"iopub.status.busy":"2022-01-09T22:44:32.101187Z","iopub.execute_input":"2022-01-09T22:44:32.101586Z","iopub.status.idle":"2022-01-09T22:44:32.139417Z","shell.execute_reply.started":"2022-01-09T22:44:32.101556Z","shell.execute_reply":"2022-01-09T22:44:32.13811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First split the data into train and test set\nfrom sklearn.model_selection import train_test_split\n\n# Split dataset into training set and test set\n# Our class column is Creditability here and everything else will be used as features \nclass_col_name='Creditability' \n\nfeature_names=df.columns[df.columns != class_col_name ]\n# 70% training and 30% test\nX_train, X_test, y_train, y_test = train_test_split(df.loc[:, feature_names], df[class_col_name], test_size=0.3,random_state=1) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:30:28.577419Z","iopub.execute_input":"2022-01-09T12:30:28.578635Z","iopub.status.idle":"2022-01-09T12:30:28.635312Z","shell.execute_reply.started":"2022-01-09T12:30:28.578584Z","shell.execute_reply":"2022-01-09T12:30:28.634598Z"},"trusted":true},"execution_count":null,"outputs":[]}]}