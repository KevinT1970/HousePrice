{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-09T11:28:32.014857Z","iopub.execute_input":"2022-01-09T11:28:32.01523Z","iopub.status.idle":"2022-01-09T11:28:32.051529Z","shell.execute_reply.started":"2022-01-09T11:28:32.015137Z","shell.execute_reply":"2022-01-09T11:28:32.050602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data_file=\"train.csv\"\n\n# data=csv.loadcsv(data_file)\n\ncsv_file = os.path.join(dirname, \"train.csv\")\n# \"/kaggle/input/house-prices-advanced-regression-techniques/\"\ncsv_data = pd.read_csv(csv_file, low_memory = False)#防止弹出警告\ndf = pd.DataFrame(csv_data)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:40:24.004997Z","iopub.execute_input":"2022-01-09T11:40:24.00545Z","iopub.status.idle":"2022-01-09T11:40:24.04021Z","shell.execute_reply.started":"2022-01-09T11:40:24.005414Z","shell.execute_reply":"2022-01-09T11:40:24.039464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df=pd.DataFrame(data[0])\nfor col in df.columns:\n  if df[col].dtype=='object':\n    #making sure data is not read as bytes but as string values from a file\n    df[col] = df[col].str.decode('utf-8')\n#Look at loaded data and data types\nprint(df.dtypes)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:28:40.366061Z","iopub.execute_input":"2022-01-09T11:28:40.366665Z","iopub.status.idle":"2022-01-09T11:28:40.532629Z","shell.execute_reply.started":"2022-01-09T11:28:40.366621Z","shell.execute_reply":"2022-01-09T11:28:40.530568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:24:31.310077Z","iopub.execute_input":"2022-01-09T11:24:31.310446Z","iopub.status.idle":"2022-01-09T11:24:31.350801Z","shell.execute_reply.started":"2022-01-09T11:24:31.3104Z","shell.execute_reply":"2022-01-09T11:24:31.349734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:24:31.352204Z","iopub.execute_input":"2022-01-09T11:24:31.35243Z","iopub.status.idle":"2022-01-09T11:24:31.388975Z","shell.execute_reply.started":"2022-01-09T11:24:31.352402Z","shell.execute_reply":"2022-01-09T11:24:31.387816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df.describe()\ndf.describe(exclude='float64')","metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:28:48.610548Z","iopub.execute_input":"2022-01-09T11:28:48.611112Z","iopub.status.idle":"2022-01-09T11:28:48.726726Z","shell.execute_reply.started":"2022-01-09T11:28:48.611076Z","shell.execute_reply":"2022-01-09T11:28:48.725821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#change YrSold, MoSold to datetime type\ndf.YrSold = pd.to_datetime(df.YrSold, format='%Y')\ndf.MoSold = pd.to_datetime(df.MoSold, format='%m')\ndf.info()\n# crime.Year = pd.to_datetime(crime.Year, format='%Y')\n# crime.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:28:53.76754Z","iopub.execute_input":"2022-01-09T11:28:53.767997Z","iopub.status.idle":"2022-01-09T11:28:53.798444Z","shell.execute_reply.started":"2022-01-09T11:28:53.767963Z","shell.execute_reply":"2022-01-09T11:28:53.797558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fail to map MSZoning to series, should find the reseaon later.\n# s = pd.Series([\"FV\",\"RH\",\"RL\",\"RM\", \"C\"],index = [1,2,3,4,5])\n# df['MSZoning']=df['MSZoning'].map({'FV':1,'RH':2,'RL':3,'RM':4, 'C':5 }).astype(int)     #将MSZoning中的字符串变成对应的数字表示\n\n# df['MSZoning']=df['MSZoning'].map({'RL':1,'RM':2,'RR':3,}).astype(int)     #将MSZoning中的字符串变成对应的数字表示","metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:29:07.341403Z","iopub.execute_input":"2022-01-09T11:29:07.341744Z","iopub.status.idle":"2022-01-09T11:29:07.441848Z","shell.execute_reply.started":"2022-01-09T11:29:07.341706Z","shell.execute_reply":"2022-01-09T11:29:07.440176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:29:18.908319Z","iopub.execute_input":"2022-01-09T11:29:18.909007Z","iopub.status.idle":"2022-01-09T11:29:18.936834Z","shell.execute_reply.started":"2022-01-09T11:29:18.908953Z","shell.execute_reply":"2022-01-09T11:29:18.93581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#use select_dtype() to filter dtype\ndf_num = df.select_dtypes(include='int64', exclude='float64')\n# df_num = df.where(Id > 3)\n# df_num = pd.DataFrame(data=df, dtype=np.int64)dt_num = np.dtype(np.int32)\n# df_num = pd.DataFrame(df, dtype=np.float64)\n# df_num = df.dtype(np.int64)\n# df_num = df.where(df['Id']<3)\n# df_num = df.where(df.dtype(int64))\n# df_num = df[[df.columns.dtype]=int64]\n# df_num = df[[df.columns.dtype]]\ndf_num.head()\n\n# df.columns\n# df_num = df[col].dtype=='object'\n# dt_num.head()\n# df_num.describe()\n# corr_num = df_num.corr()\n# print(corr_num)\n# print(corr_num)\n# corr_matrix = df.corr()\n# corr_matrix = df.corr()\n# print(corr_matrix)\n# print(which(corr_matrix != NaN)\n# print(abs(corr_matrix)>0.03)\n# main related elements: MSSubClass, LotFrontage, LotArea, MoSold, YrSold, SalePrice, PoolArea, ","metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:29:25.526116Z","iopub.execute_input":"2022-01-09T11:29:25.526411Z","iopub.status.idle":"2022-01-09T11:29:25.548637Z","shell.execute_reply.started":"2022-01-09T11:29:25.526379Z","shell.execute_reply":"2022-01-09T11:29:25.547716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#analyse the relation for number columns\ndf_num_mt = df_num.corr()\n# print(abs(df_num_mt) > 0.03)\nprint(df_num_mt)\n#and  find the most related columns from the big matrix\n# MSSubClass,LotArea, OverallQual, OverallCond,YearBuilt,YearRemodAdd,BsmtFinSF1, BsmtUnfSF,GarageCars, GarageArea,\n# WoodDeckSF,  OpenPorchSF,EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea, SalePrice ","metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:29:35.627865Z","iopub.execute_input":"2022-01-09T11:29:35.628166Z","iopub.status.idle":"2022-01-09T11:29:35.659777Z","shell.execute_reply.started":"2022-01-09T11:29:35.628133Z","shell.execute_reply":"2022-01-09T11:29:35.65889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To determine the most related elements with the saleprice through compare\n# MSSubClass,LotArea, OverallQual, OverallCond,YearBuilt,YearRemodAdd,BsmtFinSF1, BsmtUnfSF,GarageCars, GarageArea,\n# WoodDeckSF,  OpenPorchSF,EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea, SalePrice \n# df_highcorr = df[['MSSubClass'','LotArea', '''OverallQua'l'', 'Overal'l'Cond','Yea'rB'uilt','YearRemodAdd','BsmtFinSF1', 'BsmtUnfSF','GarageCars', 'GarageArea','WoodDeckSF',  'OpenPorchSF','EnclosedPorch',  '3SsnPorch',  'ScreenPorch',  'PoolArea', 'SalePrice']]\ndf_highcorr1 = df[['MSSubClass','LotArea', 'OverallQual', 'OverallCond','YearBuilt','YearRemodAdd',\n                  'BsmtFinSF1', 'BsmtUnfSF','GarageCars', 'GarageArea','WoodDeckSF',  'OpenPorchSF',\n                  'EnclosedPorch',  '3SsnPorch',  'ScreenPorch',  'PoolArea', 'SalePrice']]\n#remove the MSSubClass, 3SsnPorch, and save data to the subset.\n# these 15 columns more related.\ndf_highcorr = df[['LotArea', 'OverallQual', 'OverallCond','YearBuilt','YearRemodAdd',\n                  'BsmtFinSF1', 'BsmtUnfSF','GarageCars', 'GarageArea','WoodDeckSF',\n                  'OpenPorchSF', 'EnclosedPorch',  'ScreenPorch',  'PoolArea', 'SalePrice']].corr()\n\nprint(df_highcorr)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:30:11.816629Z","iopub.execute_input":"2022-01-09T11:30:11.816898Z","iopub.status.idle":"2022-01-09T11:30:11.837885Z","shell.execute_reply.started":"2022-01-09T11:30:11.81687Z","shell.execute_reply":"2022-01-09T11:30:11.837186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Draw the heatmap of the corralation\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# corr_matrix = df.corr()\n# sns.heatmap(corr_matrix, vmax=1, vmin=-1, center=0)\n#方法1\nmask = np.array(df_highcorr)\nmask[np.tril_indices_from(mask)] = False\nplt.subplots(figsize=(20,10))\nplt.xticks(rotation=60)#设置刻度标签角度\n# sns.heatmap(corrMat, mask=mask,vmax=.8, square=True,annot=True)\nsns.heatmap(df_highcorr, mask=mask, vmax=1, vmin=-1, center=0, cmap='Blues', fmt=\".2f\", annot=True, \n           annot_kws={'size':12,'weight':'normal', 'color':'black'})\n#方法2\n# plt.figure(dpi=120)\n# sns.heatmap(df_highcorr, vmax=1, vmin=-1, center=0, cmap='Blues', fmt=\".2f\", annot=True, \n#            annot_kws={'size':6,'weight':'normal', 'color':'black'})\n# sns.heatmap(df_highcorr, cmap='Blues')\n\nplt.show()\nplt.savefig('heatmap_corr.png')          \n","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:37:36.864701Z","iopub.execute_input":"2022-01-09T12:37:36.8652Z","iopub.status.idle":"2022-01-09T12:37:37.755288Z","shell.execute_reply.started":"2022-01-09T12:37:36.865144Z","shell.execute_reply":"2022-01-09T12:37:37.754322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# saleprice is not normal, need to clean\nsns.boxplot(y='SalePrice', data=df)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:46.785642Z","iopub.execute_input":"2022-01-09T12:39:46.785931Z","iopub.status.idle":"2022-01-09T12:39:46.943851Z","shell.execute_reply.started":"2022-01-09T12:39:46.785903Z","shell.execute_reply":"2022-01-09T12:39:46.942729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#矫正前的偏移度\nskew1 = df['SalePrice'].skew()\nprint(skew1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# saleprice is not normal, need to clean\nsns.boxplot(x='OverallQual', y='SalePrice', data=df, palette='Set3')","metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:30:27.523621Z","iopub.execute_input":"2022-01-09T11:30:27.524115Z","iopub.status.idle":"2022-01-09T11:30:27.860054Z","shell.execute_reply.started":"2022-01-09T11:30:27.524061Z","shell.execute_reply":"2022-01-09T11:30:27.859224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:30:36.834772Z","iopub.execute_input":"2022-01-09T11:30:36.835596Z","iopub.status.idle":"2022-01-09T11:30:37.022849Z","shell.execute_reply.started":"2022-01-09T11:30:36.835541Z","shell.execute_reply":"2022-01-09T11:30:37.022189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:30:41.129602Z","iopub.execute_input":"2022-01-09T11:30:41.130184Z","iopub.status.idle":"2022-01-09T11:30:41.138219Z","shell.execute_reply.started":"2022-01-09T11:30:41.130131Z","shell.execute_reply":"2022-01-09T11:30:41.137337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 对数转换：右偏数据，不适用于左偏数据,若数据中有正有负，可以如下转换：\ndf['SalePrice'] = np.sign(df['SalePrice'])*np.log(np.abs(df['SalePrice'])+1)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:40:47.553018Z","iopub.execute_input":"2022-01-09T11:40:47.55329Z","iopub.status.idle":"2022-01-09T11:40:47.56067Z","shell.execute_reply.started":"2022-01-09T11:40:47.553261Z","shell.execute_reply":"2022-01-09T11:40:47.559505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#矫正后的偏移度\nskew2 = df['SalePrice'].skew()\nprint(skew2)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:31:32.122278Z","iopub.execute_input":"2022-01-09T11:31:32.123071Z","iopub.status.idle":"2022-01-09T11:31:32.128831Z","shell.execute_reply.started":"2022-01-09T11:31:32.12303Z","shell.execute_reply":"2022-01-09T11:31:32.127941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print boxplot after adjust skew()\nsns.boxplot(y='SalePrice', data=df)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:31:55.832597Z","iopub.execute_input":"2022-01-09T11:31:55.833289Z","iopub.status.idle":"2022-01-09T11:31:56.013437Z","shell.execute_reply.started":"2022-01-09T11:31:55.833242Z","shell.execute_reply":"2022-01-09T11:31:56.012495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#打印价格的正态分布图\nimport matplotlib.pyplot as plt\n#方法1\n#正态分布的概率密度函数\ndef normpdf(x,mu,sigma):       \n    pdf=np.exp(-(x-mu)**2/(2*sigma**2))/(sigma * np.sqrt(2 * np.pi))\n    return pdf\n# mu,sigma=eval(input()) #mu:期望;sigma:标准差 \nmu = np.mean(df['SalePrice'])\nsigma = np.var(df['SalePrice'])\nx= np.arange(mu-3*sigma,mu+3*sigma,0.01) #生成数据，步长越小，曲线越平滑\ny=normpdf(x,mu,sigma)\n\n#概率分布曲线\nplt.plot(x,y,'g--',linewidth=2)\nplt.title('Normal Distribution: mu = {:.2f}, sigma={:.2f}'.format(mu,sigma))\nplt.vlines(mu, 0, normpdf(mu,mu,sigma), colors = \"c\", linestyles = \"dotted\")\nplt.vlines(mu+sigma, 0, normpdf(mu+sigma,mu,sigma), colors = \"y\", linestyles = \"dotted\")\nplt.vlines(mu-sigma, 0, normpdf(mu-sigma,mu,sigma), colors = \"y\", linestyles = \"dotted\")\nplt.xticks ([mu-sigma,mu,mu+sigma],['μ-σ','μ','μ+σ'])\n\n#输出\nplt.grid()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:43:29.172375Z","iopub.execute_input":"2022-01-09T11:43:29.17288Z","iopub.status.idle":"2022-01-09T11:43:29.390409Z","shell.execute_reply.started":"2022-01-09T11:43:29.172841Z","shell.execute_reply":"2022-01-09T11:43:29.389441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 方法2：采用seaborn库中的distplot绘制\nsns.set_palette(\"hls\") #设置所有图的颜色，使用hls色彩空间\nsns.distplot(df['SalePrice'],color=\"r\",bins=30,kde=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T11:40:55.590598Z","iopub.execute_input":"2022-01-09T11:40:55.591035Z","iopub.status.idle":"2022-01-09T11:40:55.874287Z","shell.execute_reply.started":"2022-01-09T11:40:55.591001Z","shell.execute_reply":"2022-01-09T11:40:55.87328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 方法3：\nx = df['SalePrice'] #提取变量 \nmu =np.mean(x) #计算均值 \nsigma =np.std(x) \nmu,sigma\n\nnum_bins = 30 #直方图柱子的数量 \nn, bins, patches = plt.hist(x, num_bins,normed=1, facecolor='blue', alpha=0.5) \n#直方图函数，x为x轴的值，normed=1表示为概率密度，即和为一，绿色方块，色深参数0.5.返回n个概率，直方块左边线的x值，及各个方块对象 \ny = mlab.normpdf(bins, mu, sigma)#拟合一条最佳正态分布曲线y \nplt.plot(bins, y, 'r--') #绘制y的曲线 \nplt.xlabel('sepal-length') #绘制x轴 \nplt.ylabel('Probability') #绘制y轴 \nplt.title(r'Histogram : $\\mu=5.8433$,$\\sigma=0.8253$')#中文标题 u'xxx' \nplt.subplots_adjust(left=0.15)#左边距 \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:42:52.150713Z","iopub.execute_input":"2022-01-09T12:42:52.151019Z","iopub.status.idle":"2022-01-09T12:42:52.159809Z","shell.execute_reply.started":"2022-01-09T12:42:52.150986Z","shell.execute_reply":"2022-01-09T12:42:52.158573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 方法4：另一种方法打印正态曲线\nprint('df[SalePrice] shape={}'.format(df['SalePrice'].shape))\n# df['SalePrice'].shape\ndf['SalePrice'].hist(bins=1460)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub_df = df['MSSubClass', 'SalePrice']\n# sub_df = pd.dataframe(df['Id'],df['SalePrice'])\nsubset = df[['MSSubClass','LotFrontage', 'LotArea', 'MoSold', 'YrSold', 'PoolArea', 'SalePrice']]\nprint(subset.corr())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#以下是数据清理\n#列级别的判断，只要该列有为空或者NA的元素，就为True，否则False\n# df.isnull().any()\n#将为空或者NA的列找出来\nmissing=df.columns[df.isnull().any()].tolist()  \nprint(missing)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:11:44.184151Z","iopub.execute_input":"2022-01-09T12:11:44.184703Z","iopub.status.idle":"2022-01-09T12:11:44.199137Z","shell.execute_reply.started":"2022-01-09T12:11:44.18466Z","shell.execute_reply":"2022-01-09T12:11:44.198124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[missing].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:13:41.733812Z","iopub.execute_input":"2022-01-09T12:13:41.734148Z","iopub.status.idle":"2022-01-09T12:13:41.748998Z","shell.execute_reply.started":"2022-01-09T12:13:41.734111Z","shell.execute_reply":"2022-01-09T12:13:41.747846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 将某一列中缺失元素的值，用value值进行填充。处理缺失数据时，比如该列都是字符串，不是数值，可以将出现次数最多的字符串填充缺失值。\ndef cat_imputation(column, value):\n    df.loc[df[column].isnull(),column] = value","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:15:22.0646Z","iopub.execute_input":"2022-01-09T12:15:22.065163Z","iopub.status.idle":"2022-01-09T12:15:22.068968Z","shell.execute_reply.started":"2022-01-09T12:15:22.065128Z","shell.execute_reply":"2022-01-09T12:15:22.068323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['LotFrontage','Alley']][df['Alley'].isnull()==True]      \n#从LotFrontage 和Alley 列中进行选择行，选择Alley中数据为空的行。主要用来看两个列的关联程度，是不是大多同时为空。\n","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:17:59.68061Z","iopub.execute_input":"2022-01-09T12:17:59.680877Z","iopub.status.idle":"2022-01-09T12:17:59.697707Z","shell.execute_reply.started":"2022-01-09T12:17:59.680849Z","shell.execute_reply":"2022-01-09T12:17:59.696916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Fireplaces'][df['FireplaceQu'].isnull()==True].describe()   \n#对筛选出来的数据做一个描述，比如一共多少行，均值、方差、最小值、最大值等等。","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:18:30.663606Z","iopub.execute_input":"2022-01-09T12:18:30.663887Z","iopub.status.idle":"2022-01-09T12:18:30.674857Z","shell.execute_reply.started":"2022-01-09T12:18:30.663855Z","shell.execute_reply":"2022-01-09T12:18:30.674057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['MSSubClass'].value_counts()         #统计某一列中各个元素值出现的次数","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:19:09.039912Z","iopub.execute_input":"2022-01-09T12:19:09.040201Z","iopub.status.idle":"2022-01-09T12:19:09.048322Z","shell.execute_reply.started":"2022-01-09T12:19:09.04017Z","shell.execute_reply":"2022-01-09T12:19:09.047632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Skewness: %f\" % df['MSSubClass'].skew())    #列出数据的偏斜度\nprint(\"Kurtosis: %f\" % df['MSSubClass'].kurt())  #列出数据的峰度","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:20:14.065894Z","iopub.execute_input":"2022-01-09T12:20:14.066268Z","iopub.status.idle":"2022-01-09T12:20:14.074067Z","shell.execute_reply.started":"2022-01-09T12:20:14.066228Z","shell.execute_reply":"2022-01-09T12:20:14.073065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['LotFrontage'].corr(df['LotArea'])         #计算两个列的相关度\n","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:22:17.875423Z","iopub.execute_input":"2022-01-09T12:22:17.875803Z","iopub.status.idle":"2022-01-09T12:22:17.888514Z","shell.execute_reply.started":"2022-01-09T12:22:17.875758Z","shell.execute_reply":"2022-01-09T12:22:17.88777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['SqrtLotArea']=np.sqrt(df['LotArea'])   #将列的数值求根，并赋予一个新列\ndf[['MSSubClass', 'LotFrontage']].groupby(['MSSubClass'], as_index=False).mean()  #跟MSSubClass进行分组，并求分组后的平均值","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:22:50.663606Z","iopub.execute_input":"2022-01-09T12:22:50.663913Z","iopub.status.idle":"2022-01-09T12:22:50.683501Z","shell.execute_reply.started":"2022-01-09T12:22:50.663873Z","shell.execute_reply":"2022-01-09T12:22:50.682577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df['SqrtLotArea']       #删除列\n\ndf['LotFrontage'].dropna()   #去掉为空值或者NA的元素\n\ndf.drop(['Alley'],axis=1)     #去掉Alley列，不管空值与否\n\ndf.drop(df.columns[[0,1]],axis=1,inplace=True)  #删除第1，2列，inplace=True表示直接就在内存中替换了，不用二次赋值生效。\n\ndf.dropna(axis=0)         #删除带有空值的行\n\ndf.dropna(axis=1)        #删除带有空值的列","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:24:29.902982Z","iopub.execute_input":"2022-01-09T12:24:29.903267Z","iopub.status.idle":"2022-01-09T12:24:29.962351Z","shell.execute_reply.started":"2022-01-09T12:24:29.903238Z","shell.execute_reply":"2022-01-09T12:24:29.961555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['LotFrontage']=df['LotFrontage'].fillna(0)   #将该列中的空值或者NA填充为0\n# csv_data.product_type[all_data.product_type.isnull()]=csv_data.product_type.dropna().mode().values    #如果该列是字符串的，就将该列中出现次数最多的字符串赋予空值,mode()函数就是取出现次数最多的元素。\ndf['LotFrontage'].fillna(method='pad') #使用前一个数值替代空值或者NA，就是NA前面最近的非空数值替换     \ndf['LotFrontage'].fillna(method='bfill',limit=1) #使用后一个数值替代空值或者NA，limit=1就是限制如果几个连续的空值，只能最近的一个空值可以被填充。\ndf['LotFrontage'].fillna(df['LotFrontage'].mean()) #使用平均值进行填充\ndf['LotFrontage'].interpolate() # 使用插值来估计NaN 如果index是数字，可以设置参数method='value' ，如果是时间，可以设置method='time'\ndf= df.fillna(df.mean()) #将缺失值全部用该列的平均值代替，这个时候一般已经提前将字符串特征转换成了数值。","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:30:28.577419Z","iopub.execute_input":"2022-01-09T12:30:28.578635Z","iopub.status.idle":"2022-01-09T12:30:28.635312Z","shell.execute_reply.started":"2022-01-09T12:30:28.578584Z","shell.execute_reply":"2022-01-09T12:30:28.634598Z"},"trusted":true},"execution_count":null,"outputs":[]}]}