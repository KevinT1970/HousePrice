{"metadata":{"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"},"kernelspec":{"name":"ir","display_name":"R","language":"R"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Predict the house price\n**Statement** As a new Kaggler who just created his account a day ago, I am quite excited to hand in my\nfirst submission. Without any professional background in CS/Statistics, I have learned data mining, machine learning\nand R by myself. My lack of experience may make the model not perfect, but I do love to share my opinions. And I hope \nmy dear experienced Kaggle friends can give me some advice/suggestion/criticism of this project. Thanks in advance.\n\n**Updated** Seems that I have to learn to implement XGBoost model if I want a higher score in the competition. The package\nis amazingly convenient, however I also encountered the problem of parameter tuning. Meanwhile, it seems to be true that my \nfeature engineering is too naive. With different categorical variables, I need to examine them one by one rather than transform\nthem to integer directly. I will try to do this later and see the magic of feature engineering.\n\n### Read Data and Load Packages \n\n```{r,message=FALSE, warning=FALSE}\n# Load Packages\nlibrary(MASS) \nlibrary(Metrics)\nlibrary(corrplot)\nlibrary(randomForest)\nlibrary(lars)\nlibrary(ggplot2)\nlibrary(xgboost)\nlibrary(Matrix)\nlibrary(methods)\nlibrary(caret)\n```\n```{r load}\n# Read Data\nTraining <- read.csv(\"../input/train.csv\")\nTest <- read.csv(\"../input/test.csv\")\n# Test whether data is successfully loaded\nnames(Training)\n\n```\n\nAfter that, the whole procedure has begun. I divide the whole process into four steps:\n\n* Data Cleansing\n* Descriptive Analysis\n* Model Selection\n* Final Prediction\n\n\n### Data Cleansing\nIt is important to clean the data with some specific rules, otherwise the precision of result can be jeopardized. After summarizing\ntraining set, it is not diffcult to find that some data columns got too many missing values. We first have look on the number of missing\nvalues in every variable. \n\n\n```{r,message=FALSE, warning=FALSE}\n\nNum_NA<-sapply(Training,function(y)length(which(is.na(y)==T)))\nNA_Count<- data.frame(Item=colnames(Training),Count=Num_NA)\n\nNA_Count\n```\n\nAmong 1460 variables, 'Alley',  'PoolQC', 'Fence' and 'MiscFeature' have amazingly high number of missing value. Therefore, I \nhave decided to remove those variables. After that, the number of effective variables has shrunken to 75 (excluding id). \n\n```{r,message=FALSE, warning=FALSE}\nTraining<- Training[,-c(7,73,74,75)]\n```\nThen, I transferred dummny variables into numeric form. Due to the intimidating size of dummy variables, I decided to transfer them \ndirectly by implementing 'as.integer' method. This is why I let the string as factor when reading the data file. The numeric variables\nare sorted out in particular for the convenience of descriptive analysis.\n\n```{r,message=FALSE, warning=FALSE}\n# Numeric Variables\nNum<-sapply(Training,is.numeric)\nNum<-Training[,Num]\n\nfor(i in 1:77){\n  if(is.factor(Training[,i])){\n    Training[,i]<-as.integer(Training[,i])\n  }\n}\n\n# Test\nTraining$Street[1:50]\n```\nFinally, for the remaining missing values, I replaced them with zero directly. The data cleansing procedure ends here.\n\n```{r,message=FALSE, warning=FALSE}\nTraining[is.na(Training)]<-0\nNum[is.na(Num)]<-0\n```\n### Descriptive Analysis\n\nExploring dataset could be diffcult when the quantity of variables is quite huge. Therefore, I mainly focused on the exploration of numeric\nvariables in this report. The descriptive analysis of dummy variables are mostly finished by drawing box plots. Some dummy variables, like 'Street',\nare appeared to be ineffective due to the extreme box plot. The numeric variables are sorted out before turning dummy variables into numeric form.\n\nWe first draw a corrplot of numeric variables. Those with strong correlation with sale price are examined.\n```{r,message=FALSE, warning=FALSE}\ncorrelations<- cor(Num[,-1],use=\"everything\")\ncorrplot(correlations, method=\"circle\", type=\"lower\",  sig.level = 0.01, insig = \"blank\")\n```\n'OverallQual','TotalBsmtSF','GarageCars' and 'GarageArea' have relative strong correlation with each other. Therefore, as an example, we plot the correlation\namong those four variables and SalePrice.\n```{r,message=FALSE, warning=FALSE}\npairs(~SalePrice+OverallQual+TotalBsmtSF+GarageCars+GarageArea,data=Training,\n      main=\"Scatterplot Matrix\")\n```\nThe dependent variable (SalePrice) looks having decent linearity when plotting with other variables. However, it is also obvious that some independent variables \nalso have linear relationship with others. The problem of multicollinearity is obvious and should be treated when the quantity of variables in regression formula is huge.\n\nThe final descriptive analysis I put here would be the relationship between the variable 'YearBu' and Sale Price.\n\n```{r,message=FALSE, warning=FALSE}\np<- ggplot(Training,aes(x= YearBuilt,y=SalePrice))+geom_point()+geom_smooth()\np\n```\nIt is not diffcult to find that the price of house increases generally with the year built, the trend is obvious. \n\nThe workload of data exploration is huge so I decide to end it at here. More details can be digged out by performing descriptive analysis.\n\n### Model Selection\n\nBefore implementing models, one should first split the training set of data into 2 parts: a training set within the training set and a test set that can be used for evaluation.\nPersonally I prefer to split it with the ratio of 6:4, ***But if someone can tell me what spliting ratio is proved to be scienticfic I will be really grateful***\n\n```{r,message=FALSE, warning=FALSE}\n# Split the data into Training and Test Set # Ratio: 6:4 ###\nTraining_Inner<- Training[1:floor(length(Training[,1])*0.6),]\nTest_Inner<- Training[(length(Training_Inner[,1])+1):1460,]\n```\nI will fit three regression models to the training set and choose the most suitable one by checking RMSE value.\n\n#### Model 1: Linear Regression\n\nThe first and simplest but useful model is linear regression model. As the first step, I put all variables into the model.\n```{r,message=FALSE,warning=FALSE}\nreg1<- lm(SalePrice~., data = Training_Inner)\nsummary(reg1)\n```\n\nR Square is not bad, but many variables do not pass the Hypothesis Testing, so the model is not perfect. Potential overfitting will occur if someone insist on using it. Therefore,\nthe variable selection process should be involved in model construction. I prefer to use Step AIC method.\n\nSeveral variables still should not be involved in model. By checking the result of Hypothesis Test, I mannually build the final linear regression model.\n\n```{r,message=FALSE,warning=FALSE}\nreg1_Modified_2<-lm(formula = SalePrice ~ MSSubClass + LotArea + \n                      Condition2 + OverallQual + OverallCond + \n                      YearBuilt  + RoofMatl +  ExterQual + \n                      BsmtQual + BsmtCond + BsmtFinSF1 + BsmtFinSF2 + \n                      BsmtUnfSF + X1stFlrSF + X2ndFlrSF + BedroomAbvGr + KitchenAbvGr + \n                      KitchenQual + TotRmsAbvGrd + Functional + Fireplaces + FireplaceQu + \n                       GarageYrBlt + GarageCars +  SaleCondition, \n                    data = Training_Inner)\nsummary(reg1_Modified_2)\n```\nThe R Square is not bad, and all variables pass the Hypothesis Test. The diagonsis of residuals is also not bad. The diagnosis can be viewed below.\n```{r,message=FALSE,warning=FALSE}\nlayout(matrix(c(1,2,3,4), 2, 2, byrow = TRUE))\nplot(reg1_Modified_2)\npar(mfrow=c(1,1))\n```\n\nWe check the performance of linear regression model with RMSE value.\n\n```{r,message=FALSE,warning=FALSE}\nPrediction_1<- predict(reg1_Modified_2, newdata= Test_Inner)\nrmse(log(Test_Inner$SalePrice),log(Prediction_1))\n```\n#### Model 2: LASSO Regression\n\nFor the avoidance of multicollinearity, implementing LASSO regression is not a bad idea. Transferring the variables into the form of matrix, we can automate\nthe selection of variables by implementing 'lars' method in Lars package.\n\n```{r,message=FALSE,warning=FALSE}\nIndependent_variable<- as.matrix(Training_Inner[,1:76])\nDependent_Variable<- as.matrix(Training_Inner[,77])\nlaa<- lars(Independent_variable,Dependent_Variable,type = 'lasso')\nplot(laa)\n```\n\nThe plot is messy as the quantity of variables is intimidating. Despite that, we can still use R to find out the model with least multicollinearity. The selection \nprocedure is based on the value of Marrow's cp, an important indicator of multicollinearity. The prediction can be done by the script-chosen best step and RMSE can be used\nto assess the model.\n\n```{r,message=FALSE,warning=FALSE}\nbest_step<- laa$df[which.min(laa$Cp)]\nPrediction_2<- predict.lars(laa,newx =as.matrix(Test_Inner[,1:76]), s=best_step, type= \"fit\")\nrmse(log(Test_Inner$SalePrice),log(Prediction_2$fit))\n```\n\n#### Model 3: Random Forest\n\nThe other model I chose to fit in the training set is Random Forest model. The model, prediction and RMSE calculation can be found below:\n\n```{r,message=FALSE, warning=FALSE}\nfor_1<- randomForest(SalePrice~.,data= Training_Inner)\nPrediction_3 <- predict(for_1, newdata= Test_Inner)\nrmse(log(Test_Inner$SalePrice),log(Prediction_3))\n```\n\nObviously, Random Forest may produce the best result within the training set so far. \n\n#### Model 4: XGBoost \n\nThis amazing package really impressed me! And I have enthusiam to explore it. The first step of XGBoost is to transform the dataset into Sparse matrix.\n\n```{r,message=FALSE,warning=FALSE}\ntrain<- as.matrix(Training_Inner, rownames.force=NA)\ntest<- as.matrix(Test_Inner, rownames.force=NA)\ntrain <- as(train, \"sparseMatrix\")\ntest <- as(test, \"sparseMatrix\")\n# Never forget to exclude objective variable in 'data option'\ntrain_Data <- xgb.DMatrix(data = train[,2:76], label = train[,\"SalePrice\"])\n```\nThen I tune the parameters of xgboost model by building a 20-iteration for-loop. **Not sure whether this method is reliable but really time-consuming**\n**Updated** Thanks for the advices from my fellow Kaggle friend! Now I understand how to use 'Caret' to perform grid search for the parameters. \n```{r,message=FALSE,warning=FALSE}\n# Tuning the parameters #\ncv.ctrl <- trainControl(method = \"repeatedcv\", repeats = 1,number = 3)\n\nxgb.grid <- expand.grid(nrounds = 500,\n                        max_depth = seq(6,10),\n                        eta = c(0.01,0.3, 1),\n                        gamma = c(0.0, 0.2, 1),\n                        colsample_bytree = c(0.5,0.8, 1),\n                        min_child_weight=seq(1,10)\n)\n\nxgb_tune <-train(SalePrice ~.,\n                 data=Training_Inner,\n                 method=\"xgbTree\",\n                 metric = \"RMSE\",\n                 trControl=cv.ctrl,\n                 tuneGrid=xgb.grid\n)\n\nprint(xgb.grid)\n```\nThen, the parameter can be selected by the random process. Since the process is relatively boring, I just skip it in RMarkdown file and use the optimal parameters \nI got in my local R script for the prediction and evaluation. ** Can I ask some more efficient and intelligent method of parameter tuning from smart Kagglers?\nLooking forward to your advice!!**\n\nThe model should be tested before making actual prediction.\n\n```{r,message=FALSE,warning=FALSE}\n\ntest_data <- xgb.DMatrix(data = test[,2:76])\n\nprediction <- predict(xgb_tune, test_data)\nrmse(log(Test_Inner$SalePrice),log(prediction))\n```\n\n\n\n***END*** Open to any advice/suggestion/criticism. Advice on the choice of other better models is particularily appreciated!!!!!!!!!!!!!!!!!!!!!!!!!","metadata":{"collapsed":false,"_kg_hide-input":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}